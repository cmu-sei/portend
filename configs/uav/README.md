This folder contains sample configurations and setup scripts to run the external Widnav ML process algorithm.

Pre-requisites: to be able to run the Predictor (but not for the other tools), first you have to:
1. Get the Wildnav repo at `github.com/sebastian-echeverria/wildnav`, checkout the `docker` branch with `git checkout docker`, and build the container with `bash build.sh`.
2. Put a Geotiffed map to be used as the search area, as generated by the `map_splitter.py` script in the Wildnav repo, in .`./process_io/nust/map`

In order to test the Drifter and Predictor (change run_container with run_local if you want to run this locally):

1. In the `./input/uav/sample` folder in the main folder of this repo, put the input images to be drifted or used for the Predictor.
2. Run the Helper with the 01 configuration to produce the JSON describing the dataset of images.
    - `bash run_container.sh helper --conf configs/uav/01_helper_image_json.json`
3. Run the Predictor with the 02 configuration to get the predictions for the non-drifted images.
    - `bash run_container.sh predictor --conf configs/uav/02_predictor_predict_normal_config.json`
4. Run the Drifter with the 03a configuration, to create fogged images.
    - `bash run_container.sh drifter --conf configs/uav/03a_drifter_fog_config.json`
  OR
4. Run the Drifter with the 03b configuration, to create flodded images.
    - `bash run_container.sh drifter --conf configs/uav/03b_drifter_flood_config.json`
5. Run the Predictor with the 04 configuration to get the predictions on the drifted images.
    - `bash run_container.sh predictor --conf configs/uav/04_predictor_predict_config.json`
6. Run the Predictor with any of the 05 configurations to check the metric results (a runs it on the undrifted only, b on both, using undrifted as reference, and c on drifted only, havingh specific configurations added as a reference.)
